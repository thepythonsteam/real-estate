{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01724630-9e5b-4878-a37c-cbe5a4a27760",
   "metadata": {},
   "source": [
    "# PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e28923-cebd-4593-8803-063c6c7f6d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import argparse\n",
    "import logging.config\n",
    "import typing\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "# from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor, Pool, cv\n",
    "from tqdm import tqdm\n",
    "from traceback import format_exc\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.exceptions import NotFittedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8481a491-10c8-477b-9ec2-88bd061fbea5",
   "metadata": {},
   "source": [
    "## Вспомогательные функции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275a87c1-4c08-459d-92fe-f4999186293f",
   "metadata": {},
   "source": [
    "### Настройки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9578602b-4a8e-4f47-a6ea-d530834eb00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'per_square_meter_price'\n",
    "# признаки (или набор признаков), для которых применяем smoothed target encoding\n",
    "CATEGORICAL_STE_FEATURES = ['region', 'city', 'realty_type']\n",
    "\n",
    "# признаки, для которых применяем one hot encoding\n",
    "CATEGORICAL_OHE_FEATURES = []\n",
    "\n",
    "# численные признаки \n",
    "NUM_FEATURES = ['lat', 'lng', 'osm_amenity_points_in_0.001',\n",
    "       'osm_amenity_points_in_0.005', 'osm_amenity_points_in_0.0075',\n",
    "       'osm_amenity_points_in_0.01', 'osm_building_points_in_0.001',\n",
    "       'osm_building_points_in_0.005', 'osm_building_points_in_0.0075',\n",
    "       'osm_building_points_in_0.01', 'osm_catering_points_in_0.001',\n",
    "       'osm_catering_points_in_0.005', 'osm_catering_points_in_0.0075',\n",
    "       'osm_catering_points_in_0.01', 'osm_city_closest_dist',\n",
    "       'osm_city_nearest_population',\n",
    "       'osm_crossing_closest_dist', 'osm_crossing_points_in_0.001',\n",
    "       'osm_crossing_points_in_0.005', 'osm_crossing_points_in_0.0075',\n",
    "       'osm_crossing_points_in_0.01', 'osm_culture_points_in_0.001',\n",
    "       'osm_culture_points_in_0.005', 'osm_culture_points_in_0.0075',\n",
    "       'osm_culture_points_in_0.01', 'osm_finance_points_in_0.001',\n",
    "       'osm_finance_points_in_0.005', 'osm_finance_points_in_0.0075',\n",
    "       'osm_finance_points_in_0.01', 'osm_healthcare_points_in_0.005',\n",
    "       'osm_healthcare_points_in_0.0075', 'osm_healthcare_points_in_0.01',\n",
    "       'osm_historic_points_in_0.005', 'osm_historic_points_in_0.0075',\n",
    "       'osm_historic_points_in_0.01', 'osm_hotels_points_in_0.005',\n",
    "       'osm_hotels_points_in_0.0075', 'osm_hotels_points_in_0.01',\n",
    "       'osm_leisure_points_in_0.005', 'osm_leisure_points_in_0.0075',\n",
    "       'osm_leisure_points_in_0.01', 'osm_offices_points_in_0.001',\n",
    "       'osm_offices_points_in_0.005', 'osm_offices_points_in_0.0075',\n",
    "       'osm_offices_points_in_0.01', 'osm_shops_points_in_0.001',\n",
    "       'osm_shops_points_in_0.005', 'osm_shops_points_in_0.0075',\n",
    "       'osm_shops_points_in_0.01', 'osm_subway_closest_dist',\n",
    "       'osm_train_stop_closest_dist', 'osm_train_stop_points_in_0.005',\n",
    "       'osm_train_stop_points_in_0.0075', 'osm_train_stop_points_in_0.01',\n",
    "       'osm_transport_stop_closest_dist', 'osm_transport_stop_points_in_0.005',\n",
    "       'osm_transport_stop_points_in_0.0075',\n",
    "       'osm_transport_stop_points_in_0.01',\n",
    "       'reform_count_of_houses_1000', 'reform_count_of_houses_500',\n",
    "       'reform_house_population_1000', 'reform_house_population_500',\n",
    "       'reform_mean_floor_count_1000', 'reform_mean_floor_count_500',\n",
    "       'reform_mean_year_building_1000', 'reform_mean_year_building_500','total_square']\n",
    "\n",
    "MODEL_PARAMS = dict(\n",
    "            n_estimators=2000,\n",
    "            learning_rate=0.01,\n",
    "            reg_alpha=1,\n",
    "            num_leaves=40,\n",
    "            min_child_samples=5,\n",
    "            importance_type=\"gain\",\n",
    "            n_jobs=1,\n",
    "            random_state=563,\n",
    "        )\n",
    "\n",
    "LOGGING_CONFIG = {\n",
    "    \"version\": 1,\n",
    "    \"disable_existing_loggers\": False,\n",
    "    \"formatters\": {\n",
    "        \"default\": {\"format\": \"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\"},\n",
    "    },\n",
    "    \"handlers\": {\n",
    "        \"file_handler\": {\n",
    "            \"level\": \"INFO\",\n",
    "            \"formatter\": \"default\",\n",
    "            \"class\": \"logging.FileHandler\",\n",
    "            \"filename\": 'train.log',\n",
    "            \"mode\": \"a\",\n",
    "        },\n",
    "    },\n",
    "    \"loggers\": {\n",
    "        \"\": {\"handlers\": [\"file_handler\"], \"level\": \"INFO\", \"propagate\": False},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc417f16-cf32-4203-b921-2de2de19fa6b",
   "metadata": {},
   "source": [
    "### Настройки (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eabfb35b-6d34-4a38-9329-19bbca4b0890",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'per_square_meter_price'\n",
    "# признаки (или набор признаков), для которых применяем smoothed target encoding\n",
    "CATEGORICAL_STE_FEATURES = ['region', 'city', 'realty_type']\n",
    "\n",
    "# признаки, для которых применяем one hot encoding\n",
    "CATEGORICAL_OHE_FEATURES = []\n",
    "\n",
    "# численные признаки\n",
    "NUM_FEATURES = ['lat', 'lng', 'osm_amenity_points_in_0.001',\n",
    "       'osm_amenity_points_in_0.005', 'osm_amenity_points_in_0.0075',\n",
    "       'osm_amenity_points_in_0.01', 'osm_building_points_in_0.001',\n",
    "       'osm_building_points_in_0.005', 'osm_building_points_in_0.0075',\n",
    "       'osm_building_points_in_0.01', 'osm_catering_points_in_0.001',\n",
    "       'osm_catering_points_in_0.005', 'osm_catering_points_in_0.0075',\n",
    "       'osm_catering_points_in_0.01', 'osm_city_closest_dist',\n",
    "       'osm_city_nearest_population',\n",
    "       'osm_crossing_closest_dist', 'osm_crossing_points_in_0.001',\n",
    "       'osm_crossing_points_in_0.005', 'osm_crossing_points_in_0.0075',\n",
    "       'osm_crossing_points_in_0.01', 'osm_culture_points_in_0.001',\n",
    "       'osm_culture_points_in_0.005', 'osm_culture_points_in_0.0075',\n",
    "       'osm_culture_points_in_0.01', 'osm_finance_points_in_0.001',\n",
    "       'osm_finance_points_in_0.005', 'osm_finance_points_in_0.0075',\n",
    "       'osm_finance_points_in_0.01', 'osm_healthcare_points_in_0.005',\n",
    "       'osm_healthcare_points_in_0.0075', 'osm_healthcare_points_in_0.01',\n",
    "       'osm_historic_points_in_0.005', 'osm_historic_points_in_0.0075',\n",
    "       'osm_historic_points_in_0.01', 'osm_hotels_points_in_0.005',\n",
    "       'osm_hotels_points_in_0.0075', 'osm_hotels_points_in_0.01',\n",
    "       'osm_leisure_points_in_0.005', 'osm_leisure_points_in_0.0075',\n",
    "       'osm_leisure_points_in_0.01', 'osm_offices_points_in_0.001',\n",
    "       'osm_offices_points_in_0.005', 'osm_offices_points_in_0.0075',\n",
    "       'osm_offices_points_in_0.01', 'osm_shops_points_in_0.001',\n",
    "       'osm_shops_points_in_0.005', 'osm_shops_points_in_0.0075',\n",
    "       'osm_shops_points_in_0.01', 'osm_subway_closest_dist',\n",
    "       'osm_train_stop_closest_dist', 'osm_train_stop_points_in_0.005',\n",
    "       'osm_train_stop_points_in_0.0075', 'osm_train_stop_points_in_0.01',\n",
    "       'osm_transport_stop_closest_dist', 'osm_transport_stop_points_in_0.005',\n",
    "       'osm_transport_stop_points_in_0.0075',\n",
    "       'osm_transport_stop_points_in_0.01',\n",
    "       'reform_count_of_houses_1000', 'reform_count_of_houses_500',\n",
    "       'reform_house_population_1000', 'reform_house_population_500',\n",
    "       'reform_mean_floor_count_1000', 'reform_mean_floor_count_500',\n",
    "       'reform_mean_year_building_1000', 'reform_mean_year_building_500','total_square']\n",
    "\n",
    "MODEL_PARAMS = dict(\n",
    "            n_estimators=2000,\n",
    "            learning_rate=0.01,\n",
    "            reg_alpha=1,\n",
    "            num_leaves=40,\n",
    "            min_child_samples=5,\n",
    "            importance_type=\"gain\",\n",
    "            n_jobs=1,\n",
    "            random_state=563,\n",
    "        )\n",
    "\n",
    "LOGGING_CONFIG = {\n",
    "    \"version\": 1,\n",
    "    \"disable_existing_loggers\": False,\n",
    "    \"formatters\": {\n",
    "        \"default\": {\"format\": \"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\"},\n",
    "    },\n",
    "    \"handlers\": {\n",
    "        \"file_handler\": {\n",
    "            \"level\": \"INFO\",\n",
    "            \"formatter\": \"default\",\n",
    "            \"class\": \"logging.FileHandler\",\n",
    "            \"filename\": 'train.log',\n",
    "            \"mode\": \"a\",\n",
    "        },\n",
    "    },\n",
    "    \"loggers\": {\n",
    "        \"\": {\"handlers\": [\"file_handler\"], \"level\": \"INFO\", \"propagate\": False},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596449c6-4e04-413c-a735-1261a36125a6",
   "metadata": {},
   "source": [
    "### Настройки (osm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d8bf781-320d-4800-8f28-90bb71322d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'per_square_meter_price'\n",
    "# признаки (или набор признаков), для которых применяем smoothed target encoding\n",
    "CATEGORICAL_STE_FEATURES = ['region', 'city', 'realty_type']\n",
    "\n",
    "# признаки, для которых применяем one hot encoding\n",
    "CATEGORICAL_OHE_FEATURES = []\n",
    "\n",
    "# численные признаки\n",
    "NUM_FEATURES = ['lat', 'lng', 'osm_amenity_points_in_0.001',\n",
    "       'osm_amenity_points_in_0.005', 'osm_amenity_points_in_0.0075',\n",
    "       'osm_amenity_points_in_0.01', 'osm_building_points_in_0.001',\n",
    "       'osm_building_points_in_0.005', 'osm_building_points_in_0.0075',\n",
    "       'osm_building_points_in_0.01', 'osm_catering_points_in_0.001',\n",
    "       'osm_catering_points_in_0.005', 'osm_catering_points_in_0.0075',\n",
    "       'osm_catering_points_in_0.01', 'osm_city_closest_dist',\n",
    "       'osm_city_nearest_population',\n",
    "       'osm_crossing_closest_dist', 'osm_crossing_points_in_0.001',\n",
    "       'osm_crossing_points_in_0.005', 'osm_crossing_points_in_0.0075',\n",
    "       'osm_crossing_points_in_0.01', 'osm_culture_points_in_0.001',\n",
    "       'osm_culture_points_in_0.005', 'osm_culture_points_in_0.0075',\n",
    "       'osm_culture_points_in_0.01', 'osm_finance_points_in_0.001',\n",
    "       'osm_finance_points_in_0.005', 'osm_finance_points_in_0.0075',\n",
    "       'osm_finance_points_in_0.01', 'osm_healthcare_points_in_0.005',\n",
    "       'osm_healthcare_points_in_0.0075', 'osm_healthcare_points_in_0.01',\n",
    "       'osm_historic_points_in_0.005', 'osm_historic_points_in_0.0075',\n",
    "       'osm_historic_points_in_0.01', 'osm_hotels_points_in_0.005',\n",
    "       'osm_hotels_points_in_0.0075', 'osm_hotels_points_in_0.01',\n",
    "       'osm_leisure_points_in_0.005', 'osm_leisure_points_in_0.0075',\n",
    "       'osm_leisure_points_in_0.01', 'osm_offices_points_in_0.001',\n",
    "       'osm_offices_points_in_0.005', 'osm_offices_points_in_0.0075',\n",
    "       'osm_offices_points_in_0.01', 'osm_shops_points_in_0.001',\n",
    "       'osm_shops_points_in_0.005', 'osm_shops_points_in_0.0075',\n",
    "       'osm_shops_points_in_0.01', 'osm_subway_closest_dist',\n",
    "       'osm_train_stop_closest_dist', 'osm_train_stop_points_in_0.005',\n",
    "       'osm_train_stop_points_in_0.0075', 'osm_train_stop_points_in_0.01',\n",
    "       'osm_transport_stop_closest_dist', 'osm_transport_stop_points_in_0.005',\n",
    "       'osm_transport_stop_points_in_0.0075',\n",
    "       'osm_transport_stop_points_in_0.01',\n",
    "       'reform_count_of_houses_1000', 'reform_count_of_houses_500',\n",
    "       'reform_house_population_1000', 'reform_house_population_500',\n",
    "       'reform_mean_floor_count_1000', 'reform_mean_floor_count_500',\n",
    "       'reform_mean_year_building_1000', 'reform_mean_year_building_500','total_square', \n",
    "       'poi_n_r0.001', 'poi_n_bus_stop_r0.001', 'poi_n_cafe_r0.001', 'poi_n_supermarket_r0.001',\n",
    "       'poi_n_atm_r0.001', 'poi_n_bank_r0.001', 'poi_n_clothes_r0.001', 'poi_n_fast_food_r0.001',\n",
    "       'poi_n_hairdresser_r0.001', 'poi_n_restaurant_r0.001', 'poi_n_tram_stop_r0.001',\n",
    "       'poi_n_Sberbank', 'poi_closest_Sberbank', 'poi_n_Pjaterochka', 'poi_closest_Pjaterochka',\n",
    "       'poi_n_Magnit', 'poi_closest_Magnit', 'poi_n_DNS', 'poi_closest_DNS',\n",
    "       'poi_n_Diksi', 'poi_closest_Diksi', 'poi_n_Krasnoe__Beloe', 'poi_closest_Krasnoe__Beloe',\n",
    "       'poi_n_KrasnoeBeloe', 'poi_closest_KrasnoeBeloe', 'poi_n_MTS', 'poi_closest_MTS',\n",
    "       'poi_n_VTB', 'poi_closest_VTB', 'poi_n_Coffee_Like', 'poi_closest_Coffee_Like',\n",
    "       'poi_n_Stolovaja', 'poi_closest_Stolovaja', 'poi_n_Svjaznoj', 'poi_closest_Svjaznoj',\n",
    "       'poi_n_Bristol', 'poi_closest_Bristol', 'poi_n_Burger_King', 'poi_closest_Burger_King',\n",
    "       'poi_n_Alfa-Bank', 'poi_closest_Alfa-Bank', 'poi_n_r0.002', 'poi_n_bus_stop_r0.002',\n",
    "       'poi_n_cafe_r0.002', 'poi_n_supermarket_r0.002', 'poi_n_atm_r0.002', 'poi_n_bank_r0.002',\n",
    "       'poi_n_clothes_r0.002', 'poi_n_fast_food_r0.002', 'poi_n_hairdresser_r0.002',\n",
    "       'poi_n_restaurant_r0.002', 'poi_n_tram_stop_r0.002']\n",
    "\n",
    "MODEL_PARAMS = dict(\n",
    "            n_estimators=2000,\n",
    "            learning_rate=0.01,\n",
    "            reg_alpha=1,\n",
    "            num_leaves=40,\n",
    "            min_child_samples=5,\n",
    "            importance_type=\"gain\",\n",
    "            n_jobs=1,\n",
    "            random_state=563,\n",
    "        )\n",
    "\n",
    "LOGGING_CONFIG = {\n",
    "    \"version\": 1,\n",
    "    \"disable_existing_loggers\": False,\n",
    "    \"formatters\": {\n",
    "        \"default\": {\"format\": \"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\"},\n",
    "    },\n",
    "    \"handlers\": {\n",
    "        \"file_handler\": {\n",
    "            \"level\": \"INFO\",\n",
    "            \"formatter\": \"default\",\n",
    "            \"class\": \"logging.FileHandler\",\n",
    "            \"filename\": 'train.log',\n",
    "            \"mode\": \"a\",\n",
    "        },\n",
    "    },\n",
    "    \"loggers\": {\n",
    "        \"\": {\"handlers\": [\"file_handler\"], \"level\": \"INFO\", \"propagate\": False},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8548f234-899d-40bf-b582-b6d0bb283f16",
   "metadata": {},
   "source": [
    "### Настройки (catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c1499ce-c2a4-40d4-9f84-d2caf39bcf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'per_square_meter_price'\n",
    "# признаки (или набор признаков), для которых применяем smoothed target encoding\n",
    "CATEGORICAL_STE_FEATURES = ['region', 'city', 'realty_type']\n",
    "\n",
    "# признаки, для которых применяем one hot encoding\n",
    "CATEGORICAL_OHE_FEATURES = []\n",
    "\n",
    "# численные признаки\n",
    "NUM_FEATURES = ['lat', 'lng', 'osm_amenity_points_in_0.001',\n",
    "       'osm_amenity_points_in_0.005', 'osm_amenity_points_in_0.0075',\n",
    "       'osm_amenity_points_in_0.01', 'osm_building_points_in_0.001',\n",
    "       'osm_building_points_in_0.005', 'osm_building_points_in_0.0075',\n",
    "       'osm_building_points_in_0.01', 'osm_catering_points_in_0.001',\n",
    "       'osm_catering_points_in_0.005', 'osm_catering_points_in_0.0075',\n",
    "       'osm_catering_points_in_0.01', 'osm_city_closest_dist',\n",
    "       'osm_city_nearest_population',\n",
    "       'osm_crossing_closest_dist', 'osm_crossing_points_in_0.001',\n",
    "       'osm_crossing_points_in_0.005', 'osm_crossing_points_in_0.0075',\n",
    "       'osm_crossing_points_in_0.01', 'osm_culture_points_in_0.001',\n",
    "       'osm_culture_points_in_0.005', 'osm_culture_points_in_0.0075',\n",
    "       'osm_culture_points_in_0.01', 'osm_finance_points_in_0.001',\n",
    "       'osm_finance_points_in_0.005', 'osm_finance_points_in_0.0075',\n",
    "       'osm_finance_points_in_0.01', 'osm_healthcare_points_in_0.005',\n",
    "       'osm_healthcare_points_in_0.0075', 'osm_healthcare_points_in_0.01',\n",
    "       'osm_historic_points_in_0.005', 'osm_historic_points_in_0.0075',\n",
    "       'osm_historic_points_in_0.01', 'osm_hotels_points_in_0.005',\n",
    "       'osm_hotels_points_in_0.0075', 'osm_hotels_points_in_0.01',\n",
    "       'osm_leisure_points_in_0.005', 'osm_leisure_points_in_0.0075',\n",
    "       'osm_leisure_points_in_0.01', 'osm_offices_points_in_0.001',\n",
    "       'osm_offices_points_in_0.005', 'osm_offices_points_in_0.0075',\n",
    "       'osm_offices_points_in_0.01', 'osm_shops_points_in_0.001',\n",
    "       'osm_shops_points_in_0.005', 'osm_shops_points_in_0.0075',\n",
    "       'osm_shops_points_in_0.01', 'osm_subway_closest_dist',\n",
    "       'osm_train_stop_closest_dist', 'osm_train_stop_points_in_0.005',\n",
    "       'osm_train_stop_points_in_0.0075', 'osm_train_stop_points_in_0.01',\n",
    "       'osm_transport_stop_closest_dist', 'osm_transport_stop_points_in_0.005',\n",
    "       'osm_transport_stop_points_in_0.0075',\n",
    "       'osm_transport_stop_points_in_0.01',\n",
    "       'reform_count_of_houses_1000', 'reform_count_of_houses_500',\n",
    "       'reform_house_population_1000', 'reform_house_population_500',\n",
    "       'reform_mean_floor_count_1000', 'reform_mean_floor_count_500',\n",
    "       'reform_mean_year_building_1000', 'reform_mean_year_building_500','total_square', \n",
    "       'poi_n_r0.001', 'poi_n_bus_stop_r0.001', 'poi_n_cafe_r0.001', 'poi_n_supermarket_r0.001',\n",
    "       'poi_n_atm_r0.001', 'poi_n_bank_r0.001', 'poi_n_clothes_r0.001', 'poi_n_fast_food_r0.001',\n",
    "       'poi_n_hairdresser_r0.001', 'poi_n_restaurant_r0.001', 'poi_n_tram_stop_r0.001']\n",
    "\n",
    "MODEL_PARAMS = {\n",
    "    'depth': 8, \n",
    "    'verbose': 50,\n",
    "    'iterations': 1500,\n",
    "    'loss_function': 'RMSE',\n",
    "    'eval_metric': 'R2',\n",
    "    'learning_rate': 0.15,\n",
    "    'random_state': 5\n",
    "}\n",
    "\n",
    "LOGGING_CONFIG = {\n",
    "    \"version\": 1,\n",
    "    \"disable_existing_loggers\": False,\n",
    "    \"formatters\": {\n",
    "        \"default\": {\"format\": \"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\"},\n",
    "    },\n",
    "    \"handlers\": {\n",
    "        \"file_handler\": {\n",
    "            \"level\": \"INFO\",\n",
    "            \"formatter\": \"default\",\n",
    "            \"class\": \"logging.FileHandler\",\n",
    "            \"filename\": 'train.log',\n",
    "            \"mode\": \"a\",\n",
    "        },\n",
    "    },\n",
    "    \"loggers\": {\n",
    "        \"\": {\"handlers\": [\"file_handler\"], \"level\": \"INFO\", \"propagate\": False},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bf5b76-6bcb-4ccd-9cda-804778a2affd",
   "metadata": {},
   "source": [
    "### Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "833775a9-4487-4e36-a616-9242a9345f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.15\n",
    "NEGATIVE_WEIGHT = 1.1\n",
    "EPS = 1e-8\n",
    "\n",
    "def deviation_metric_one_sample(y_true: typing.Union[float, int], y_pred: typing.Union[float, int]) -> float:\n",
    "    \"\"\"\n",
    "    Реализация кастомной метрики для хакатона.\n",
    "\n",
    "    :param y_true: float, реальная цена\n",
    "    :param y_pred: float, предсказанная цена\n",
    "    :return: float, значение метрики\n",
    "    \"\"\"\n",
    "    deviation = (y_pred - y_true) / np.maximum(1e-8, y_true)\n",
    "    if np.abs(deviation) <= THRESHOLD:\n",
    "        return 0\n",
    "    elif deviation <= - 4 * THRESHOLD:\n",
    "        return 9 * NEGATIVE_WEIGHT\n",
    "    elif deviation < -THRESHOLD:\n",
    "        return NEGATIVE_WEIGHT * ((deviation / THRESHOLD) + 1) ** 2\n",
    "    elif deviation < 4 * THRESHOLD:\n",
    "        return ((deviation / THRESHOLD) - 1) ** 2\n",
    "    else:\n",
    "        return 9\n",
    "\n",
    "\n",
    "def deviation_metric(y_true: np.array, y_pred: np.array) -> float:\n",
    "    return np.array([deviation_metric_one_sample(y_true[n], y_pred[n]) for n in range(len(y_true))]).mean()\n",
    "\n",
    "def median_absolute_percentage_error(y_true: np.array, y_pred: np.array) -> float:\n",
    "    return np.median(np.abs(y_pred-y_true)/y_true)\n",
    "\n",
    "def metrics_stat(y_true: np.array, y_pred: np.array) -> typing.Dict[str,float]:\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    mdape = median_absolute_percentage_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    raif_metric = deviation_metric(y_true, y_pred)\n",
    "    return {'mape':mape, 'mdape':mdape, 'rmse': rmse, 'r2': r2, 'raif_metric':raif_metric}\n",
    "\n",
    "# TODO спросить Сашу\n",
    "# assert deviation_metric(np.array([1,2,3,4,5]),np.array([1,2,3,4,5])) <= EPS\n",
    "# assert deviation_metric(np.array([1,2,3,4,5]),np.array([0.9,1.8,2.7,3.6,4.5])) <= EPS\n",
    "# assert deviation_metric(np.array([1,2,3,4,5]),np.array([1.1,2.2,3.3,4.4,5.5])) <= EPS\n",
    "# assert deviation_metric(np.array([1,2,3,4,5]),np.array([1.15,2.3,3.45,4.6,5.75])) <= EPS\n",
    "# assert np.abs(deviation_metric(np.array([1,2,3,4,5]),np.array([1.3,2.6,3.9,5.2,6.5]))-1) <= EPS\n",
    "# assert np.abs(deviation_metric(np.array([1,2,3,4,5]),np.array([0.7,1.4,2.1,2.8,3.5]))-1*NEGATIVE_WEIGHT) <= EPS\n",
    "# assert np.abs(deviation_metric(np.array([1,2,3,4,5]),np.array([10,20,30,40,50]))-9) <= EPS\n",
    "# assert np.abs(deviation_metric(np.array([1,2,3,4,5]),np.array([0,0,0,0,0]))-9*NEGATIVE_WEIGHT) <= EPS\n",
    "# assert np.abs(deviation_metric(np.array([1,2,3,4,5]),np.array([1,2.2,3.3,5,50])) - 85/45) <= EPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965079b4-397b-44d3-b7f0-61489e1d7cd3",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5383d38b-958d-4b9c-bbe7-fb26a3550525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum  import IntEnum\n",
    "\n",
    "UNKNOWN_VALUE = 'missing'\n",
    "\n",
    "class PriceTypeEnum(IntEnum):\n",
    "\n",
    "    OFFER_PRICE = 0 # цена из объявления\n",
    "    MANUAL_PRICE = 1 # цена, полученная путем ручной оценки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65367566-0b9f-41c3-8be8-e9b52fde3dbe",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "280faf96-e88d-44b0-b81c-4e6c4af73eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_categorical(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Заполняет пропущенные категориальные переменные\n",
    "    :param df: dataframe, обучающая выборка\n",
    "    :return: dataframe\n",
    "    \"\"\"\n",
    "    df_new = df.copy()\n",
    "    fillna_cols = ['region','city','street','realty_type']\n",
    "    df_new[fillna_cols] = df_new[fillna_cols].fillna(UNKNOWN_VALUE)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5576c8a9-1738-45de-92d4-5ba14c4fdcf6",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0879b44-2321-4d63-b9fd-d38a5fe52db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class BenchmarkModel():\n",
    "    \"\"\"\n",
    "    Модель представляет из себя sklearn pipeline. Пошаговый алгоритм:\n",
    "      1) в качестве обучения выбираются все данные с price_type=0\n",
    "      1) все фичи делятся на три типа (numerical_features, ohe_categorical_features, ste_categorical_features):\n",
    "          1.1) numerical_features - применяется StandardScaler\n",
    "          1.2) ohe_categorical_featires - кодируются через one hot encoding\n",
    "          1.3) ste_categorical_features - кодируются через SmoothedTargetEncoder\n",
    "      2) после этого все полученные фичи конкатенируются в одно пространство фичей и подаются на вход модели Lightgbm\n",
    "      3) делаем предикт на данных с price_type=1, считаем среднее отклонение реальных значений от предикта. Вычитаем это отклонение на финальном шаге (чтобы сместить отклонение к 0)\n",
    "\n",
    "    :param numerical_features: list, список численных признаков из датафрейма\n",
    "    :param ohe_categorical_features: list, список категориальных признаков для one hot encoding\n",
    "    :param ste_categorical_features, list, список категориальных признаков для smoothed target encoding.\n",
    "                                     Можно кодировать сразу несколько полей (например объединять категориальные признаки)\n",
    "    :\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, numerical_features: typing.List[str],\n",
    "                 ohe_categorical_features: typing.List[str],\n",
    "                 ste_categorical_features: typing.List[typing.Union[str, typing.List[str]]],\n",
    "                 model_params: typing.Dict[str, typing.Union[str,int,float]]):\n",
    "        self.num_features = numerical_features\n",
    "        self.ohe_cat_features = ohe_categorical_features\n",
    "        self.ste_cat_features = ste_categorical_features\n",
    "\n",
    "        self.preprocessor = ColumnTransformer(transformers=[\n",
    "            ('num', StandardScaler(), self.num_features),\n",
    "            ('ohe', OneHotEncoder(), self.ohe_cat_features),\n",
    "            ('ste', OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1),\n",
    "             self.ste_cat_features)])\n",
    "\n",
    "#         self.model = LGBMRegressor(**model_params)\n",
    "        self.model = CatBoostRegressor(**model_params)\n",
    "\n",
    "        self.pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', self.preprocessor),\n",
    "            ('model', self.model)])\n",
    "\n",
    "        self._is_fitted = False\n",
    "        self.corr_coef = 0\n",
    "\n",
    "    def _find_corr_coefficient(self, X_manual: pd.DataFrame, y_manual: pd.Series):\n",
    "        \"\"\"Вычисление корректирующего коэффициента\n",
    "\n",
    "        :param X_manual: pd.DataFrame с ручными оценками\n",
    "        :param y_manual: pd.Series - цены ручника\n",
    "        \"\"\"\n",
    "        predictions = self.pipeline.predict(X_manual)\n",
    "        deviation = ((y_manual - predictions)/predictions).median()\n",
    "        self.corr_coef = deviation\n",
    "\n",
    "    def fit(self, X_offer: pd.DataFrame, y_offer: pd.Series,\n",
    "            X_manual: pd.DataFrame, y_manual: pd.Series):\n",
    "        \"\"\"Обучение модели.\n",
    "        ML модель обучается на данных по предложениям на рынке (цены из объявления)\n",
    "        Затем вычисляется среднее отклонение между руяными оценками и предиктами для корректировки стоимости\n",
    "\n",
    "        :param X_offer: pd.DataFrame с объявлениями\n",
    "        :param y_offer: pd.Series - цена предложения (в объявлениях)\n",
    "        :param X_manual: pd.DataFrame с ручными оценками\n",
    "        :param y_manual: pd.Series - цены ручника\n",
    "        \"\"\"\n",
    "        logger.info('Fit lightgbm')\n",
    "        self.pipeline.fit(X_offer, y_offer, model__feature_name=[f'{i}' for i in range(125)],model__categorical_feature=['67','68','69'])\n",
    "        logger.info('Find corr coefficient')\n",
    "        self._find_corr_coefficient(X_manual, y_manual)\n",
    "        logger.info(f'Corr coef: {self.corr_coef:.2f}')\n",
    "        self.__is_fitted = True\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> np.array:\n",
    "        \"\"\"Предсказание модели Предсказываем преобразованный таргет, затем конвертируем в обычную цену через обратное\n",
    "        преобразование.\n",
    "\n",
    "        :param X: pd.DataFrame\n",
    "        :return: np.array, предсказания (цены на коммерческую недвижимость)\n",
    "        \"\"\"\n",
    "        if self.__is_fitted:\n",
    "            predictions = self.pipeline.predict(X)\n",
    "            corrected_price = predictions * (1 + self.corr_coef)\n",
    "            return corrected_price\n",
    "        else:\n",
    "            raise NotFittedError(\n",
    "                \"This {} instance is not fitted yet! Call 'fit' with appropriate arguments before predict\".format(\n",
    "                    type(self).__name__\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def save(self, path: str):\n",
    "        \"\"\"Сериализует модель в pickle.\n",
    "\n",
    "        :param path: str, путь до файла\n",
    "        \"\"\"\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load(self, path: str):\n",
    "        \"\"\"Сериализует модель в pickle.\n",
    "\n",
    "        :param path: str, путь до файла\n",
    "        :return: Модель\n",
    "        \"\"\"\n",
    "        with open(path, \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44198eae-0e84-4b78-a8eb-6de02c0dd0af",
   "metadata": {},
   "source": [
    "## Запуск"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb844ee-adec-402d-b45e-066ce5e12c41",
   "metadata": {},
   "source": [
    "### Запуск обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "266a8369-d796-4d5f-81ce-9262adeae5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.config.dictConfig(LOGGING_CONFIG)\n",
    "logger = logging.getLogger(__name__)\n",
    "path_to_train = '../data/df_train_with_poi.zip'\n",
    "path_to_test = '../data/df_test_with_poi.zip'\n",
    "path_to_save_model = '../models/test.pickle'\n",
    "\n",
    "try:\n",
    "#   START train\n",
    "#   Load train df\n",
    "\n",
    "    zip_file = zipfile.ZipFile(path_to_train)\n",
    "    train_df = pd.read_csv(zip_file.open(zip_file.namelist()[0]), low_memory=False)\n",
    "#   Input shape: {train_df.shape}\n",
    "    train_df = prepare_categorical(train_df)\n",
    "\n",
    "    X_offer = train_df[train_df.price_type == PriceTypeEnum.OFFER_PRICE]\n",
    "    [NUM_FEATURES+CATEGORICAL_OHE_FEATURES+CATEGORICAL_STE_FEATURES]\n",
    "    \n",
    "    y_offer = train_df[train_df.price_type == PriceTypeEnum.OFFER_PRICE][TARGET]\n",
    "    \n",
    "    X_manual = train_df[train_df.price_type == PriceTypeEnum.MANUAL_PRICE]\n",
    "    [NUM_FEATURES+CATEGORICAL_OHE_FEATURES+CATEGORICAL_STE_FEATURES]\n",
    "    \n",
    "    y_manual = train_df[train_df.price_type == PriceTypeEnum.MANUAL_PRICE][TARGET]\n",
    "#     logger.info(f'X_offer {X_offer.shape}  y_offer {y_offer.shape}\\tX_manual {X_manual.shape} y_manual {y_manual.shape}')\n",
    "    \n",
    "    model = BenchmarkModel(numerical_features=NUM_FEATURES, ohe_categorical_features=CATEGORICAL_OHE_FEATURES,\n",
    "                              ste_categorical_features=CATEGORICAL_STE_FEATURES, model_params=MODEL_PARAMS)\n",
    "    \n",
    "#   Fit model\n",
    "    model.fit(X_offer, y_offer, X_manual, y_manual)\n",
    "#   'Save model'\n",
    "    model.save(path_to_save_model)\n",
    "\n",
    "    predictions_offer = model.predict(X_offer)\n",
    "    metrics = metrics_stat(y_offer.values, predictions_offer/(1+model.corr_coef)) # для обучающей выборки с ценами из объявлений смотрим качество без коэффициента\n",
    "    print('Metrics stat for training data with offers prices:', metrics)\n",
    "\n",
    "    predictions_manual = model.predict(X_manual)\n",
    "    metrics = metrics_stat(y_manual.values, predictions_manual)\n",
    "    print('Metrics stat for training data with manual prices:', metrics)\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    err = format_exc()\n",
    "    print('ERROR')\n",
    "#     raise(e)\n",
    "logger.info('END train.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5b0c4b8c-6473-4dcf-98be-2783034f3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file = zipfile.ZipFile(path_to_train)\n",
    "train_df = pd.read_csv(zip_file.open(zip_file.namelist()[0]), low_memory=False)\n",
    "\n",
    "train_df = prepare_categorical(train_df)\n",
    "\n",
    "X_offer = train_df[train_df.price_type == PriceTypeEnum.OFFER_PRICE]\n",
    "[NUM_FEATURES+CATEGORICAL_OHE_FEATURES+CATEGORICAL_STE_FEATURES]\n",
    "\n",
    "y_offer = train_df[train_df.price_type == PriceTypeEnum.OFFER_PRICE][TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5e0f0405-391b-4cb3-8b5b-6aacf9729313",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'feature_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-e3af8221a70d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_offer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_manual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_manual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-0fb92a679253>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_offer, y_offer, X_manual, y_manual)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"\"\"\n\u001b[1;32m     66\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fit lightgbm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_offer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel__feature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{i}'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel__categorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'67'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'68'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'69'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Find corr coefficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_corr_coefficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_manual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_manual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'feature_name'"
     ]
    }
   ],
   "source": [
    "X_manual = train_df[train_df.price_type == PriceTypeEnum.MANUAL_PRICE]\n",
    "[NUM_FEATURES+CATEGORICAL_OHE_FEATURES+CATEGORICAL_STE_FEATURES]\n",
    "\n",
    "y_manual = train_df[train_df.price_type == PriceTypeEnum.MANUAL_PRICE][TARGET]\n",
    "\n",
    "\n",
    "model = BenchmarkModel(numerical_features=NUM_FEATURES, ohe_categorical_features=CATEGORICAL_OHE_FEATURES, \n",
    "                       ste_categorical_features=CATEGORICAL_STE_FEATURES, model_params=MODEL_PARAMS)\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_offer, y_offer, X_manual, y_manual)\n",
    "\n",
    "# Save model\n",
    "# model.save(path_to_save_model)\n",
    "\n",
    "# predictions_offer = model.predict(X_offer)\n",
    "# metrics = metrics_stat(y_offer.values, predictions_offer/(1+model.corr_coef)) # для обучающей выборки с ценами из объявлений смотрим качество без коэффициента\n",
    "# print('Metrics stat for training data with offers prices:', metrics)\n",
    "\n",
    "# predictions_manual = model.predict(X_manual)\n",
    "# metrics = metrics_stat(y_manual.values, predictions_manual)\n",
    "# print('Metrics stat for training data with manual prices:', metrics)\n",
    "\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15ea6cb-deae-4e4d-9863-08fe30709f87",
   "metadata": {},
   "source": [
    "### Запуск предикта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "558ca2db-14db-477f-96e9-806cdf35a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.config.dictConfig(LOGGING_CONFIG)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "275d4a8e-0894-436d-afd6-c0c4d7273675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"\"\"\n",
    "    Бенчмарк для хакатона по предсказанию стоимости коммерческой недвижимости от \"Райффайзенбанк\"\n",
    "    Скрипт для предсказания модели\n",
    "     \n",
    "     Примеры:\n",
    "        1) с poetry - poetry run python3 predict.py --test_data /path/to/test/data --model_path /path/to/model --output /path/to/output/file.csv.gzip\n",
    "        2) без poetry - python3 predict.py --test_data /path/to/test/data --model_path /path/to/model --output /path/to/output/file.csv.gzip\n",
    "    \"\"\",\n",
    "        formatter_class=argparse.RawTextHelpFormatter,\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\"--test_data\", \"-d\", type=str, dest=\"d\", required=True, help=\"Путь до отложенной выборки\")\n",
    "    parser.add_argument(\"--model_path\", \"-mp\", type=str, dest=\"mp\", required=True,\n",
    "                        help=\"Пусть до сериализованной ML модели\")\n",
    "    parser.add_argument(\"--output\", \"-o\", type=str, dest=\"o\", required=True, help=\"Путь до выходного файла\")\n",
    "\n",
    "    return parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98468b58-a150-46eb-b3e8-a01b3931b6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    path_to_pickled_model = '../models/test.pickle'\n",
    "    path_to_test_data = '../data/df_test_with_poi.zip'\n",
    "\n",
    "    test_df = pd.read_csv(path_to_test_data, compression='zip')\n",
    "\n",
    "    test_df = prepare_categorical(test_df)\n",
    "\n",
    "\n",
    "    model = BenchmarkModel.load(path_to_pickled_model)\n",
    "\n",
    "    test_df['per_square_meter_price'] = model.predict(test_df[NUM_FEATURES+CATEGORICAL_OHE_FEATURES+CATEGORICAL_STE_FEATURES])\n",
    "\n",
    "    test_df[['id','per_square_meter_price']].to_csv(args['o'], index=False)\n",
    "except Exception as e:\n",
    "    print('ERROR')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
